<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CSV Tools - DuckDB + Pyodide Version</title>
    
    <!-- CodeMirror for SQL editing -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.16/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.16/mode/sql/sql.min.js"></script>
    
    <!-- PyScript for DuckDB integration -->
    <script type="module" src="https://pyscript.net/releases/2024.8.2/core.js"></script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.65.16/codemirror.min.css">
    <link rel="stylesheet" href="css/style.css">
    
    <style>
        .version-badge {
            background: #f39c12;
            color: white;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.8em;
            margin-left: 10px;
        }
        .loading-progress {
            width: 100%;
            height: 4px;
            background: #ecf0f1;
            border-radius: 2px;
            overflow: hidden;
            margin-top: 10px;
        }
        .loading-bar {
            height: 100%;
            background: linear-gradient(90deg, #3498db, #9b59b6);
            border-radius: 2px;
            transition: width 0.3s ease;
            width: 0%;
        }
    </style>
</head>
<body>
    <div id="app">
        <header>
            <h1>CSV Tools <span class="version-badge">DuckDB + Pyodide</span></h1>
            <p>Upload CSV/Excel files and query with full SQL - DuckDB-powered</p>
            <div id="loading-status">Initializing Pyodide environment...</div>
            <div class="loading-progress">
                <div class="loading-bar" id="loading-bar"></div>
            </div>
        </header>
        
        <div id="upload-section" style="display: none;">
            <h2>Upload Files</h2>
            <div id="dropzone" class="dropzone">
                <div class="dz-message">
                    <strong>Drop CSV/Excel files here or click to upload</strong>
                    <span class="note">(Supports .csv, .xlsx files - Max size: 50MB)</span>
                </div>
            </div>
            <div id="file-list"></div>
        </div>
        
        <div id="query-section" style="display: none;">
            <h2>SQL Query</h2>
            <div id="sql-editor"></div>
            <div class="query-controls">
                <button id="run-query">Run Query</button>
                <span class="shortcut-hint">Ctrl+Enter to run</span>
                <div class="query-examples">
                    <select id="example-queries">
                        <option value="">Load example query...</option>
                        <option value="SELECT * FROM t1 LIMIT 10;">Basic SELECT</option>
                        <option value="SELECT column, COUNT(*) as count FROM t1 GROUP BY column ORDER BY count DESC;">Group By Count</option>
                        <option value="SELECT * FROM t1 JOIN t2 ON t1.id = t2.id;">Inner Join</option>
                        <option value="SELECT *, ROW_NUMBER() OVER (PARTITION BY category ORDER BY value DESC) as rank FROM t1;">Window Function</option>
                    </select>
                </div>
            </div>
        </div>
        
        <div id="results-section" style="display: none;">
            <h2>Results</h2>
            <div id="query-info" class="query-info"></div>
            <div id="results-table"></div>
            <div class="export-controls">
                <button id="export-csv">Export as CSV</button>
            </div>
        </div>
        
        <div id="error-container"></div>
    </div>
    
    <!-- DuckDB Python Module -->
    <script type="py" config='{"packages":["duckdb"]}' id="python-code">
import duckdb
import io
import base64
from js import console, document, File, Blob, URL
import asyncio

class DuckDBCSVTools:
    def __init__(self):
        self.conn = duckdb.connect(':memory:')
        self.excel_extension_available = False
        
        # Install and load Excel extension
        try:
            console.log("Attempting to install Excel extension...")
            self.conn.execute("INSTALL excel")
            console.log("Excel extension installed, loading...")
            self.conn.execute("LOAD excel")
            
            # Test if Excel extension is working
            console.log("Testing Excel extension functionality...")
            test_result = self.conn.execute("SELECT extension_name FROM duckdb_extensions() WHERE extension_name = 'excel'").fetchall()
            if test_result:
                self.excel_extension_available = True
                console.log("DuckDB with Excel support initialized successfully")
            else:
                console.log("Excel extension installed but not found in extensions list")
                
        except Exception as e:
            console.error(f"Excel extension initialization failed: {e}")
            console.log("DuckDB initialized without Excel support - will use fallback for Excel files")
        
        self.tables = {}
        self.table_counter = 1
    
    def load_csv_file(self, file_content, filename, has_headers=True):
        """Load CSV data into DuckDB table using pure DuckDB"""
        try:
            # Generate table name
            table_name = f"t{self.table_counter}"
            self.table_counter += 1
            
            # Use DuckDB's read_csv with direct string content
            lines = file_content.strip().split('\n')
            
            if has_headers:
                header = lines[0].split(',')
                data_start_line = 1
            else:
                # Generate c1, c2, c3... headers
                first_row = lines[0].split(',')
                header = [f"c{i+1}" for i in range(len(first_row))]
                data_start_line = 0
            
            # Clean up header names (remove quotes if present)
            clean_header = [col.strip().strip('"\'') for col in header]
            
            # Create the table schema first
            columns_sql = ', '.join([f'"{col}" VARCHAR' for col in clean_header])
            self.conn.execute(f"CREATE TABLE {table_name} ({columns_sql})")
            
            # Insert data row by row
            for line in lines[data_start_line:]:
                if line.strip():  # Skip empty lines
                    # Parse CSV line (basic parsing - handles quoted fields)
                    values = []
                    current_value = ""
                    in_quotes = False
                    
                    for char in line:
                        if char == '"' and not in_quotes:
                            in_quotes = True
                        elif char == '"' and in_quotes:
                            in_quotes = False
                        elif char == ',' and not in_quotes:
                            values.append(current_value.strip().strip('"\''))
                            current_value = ""
                        else:
                            current_value += char
                    
                    # Add the last value
                    values.append(current_value.strip().strip('"\''))
                    
                    # Insert the row
                    if len(values) == len(clean_header):
                        placeholders = ', '.join(['?' for _ in values])
                        self.conn.execute(f"INSERT INTO {table_name} VALUES ({placeholders})", values)
            
            # Get table info
            count_result = self.conn.execute(f"SELECT COUNT(*) as count FROM {table_name}").fetchone()
            row_count = count_result[0]
            
            # Store metadata
            self.tables[table_name] = {
                'filename': filename,
                'rows': row_count,
                'columns': clean_header,
                'size': len(file_content),
                'has_headers': has_headers
            }
            
            console.log(f"Loaded {filename} as {table_name} with {row_count} rows and {len(clean_header)} columns (has_headers: {has_headers})")
            return {
                'table_name': table_name,
                'rows': row_count,
                'columns': clean_header,
                'success': True,
                'has_headers': has_headers
            }
            
        except Exception as e:
            console.error(f"Failed to load CSV {filename}: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def load_excel_file(self, file_content, filename):
        """Load Excel data into DuckDB table using official Excel extension or fallback"""
        try:
            console.log(f"Starting Excel file processing for {filename}")
            console.log(f"Excel extension available: {self.excel_extension_available}")
            
            # Decode base64 content to bytes
            file_bytes = base64.b64decode(file_content)
            console.log(f"Decoded {len(file_bytes)} bytes from base64")
            
            # Generate table name
            table_name = f"t{self.table_counter}"
            self.table_counter += 1
            
            if not self.excel_extension_available:
                console.log("Excel extension not available, using fallback method")
                return self.load_excel_fallback(file_bytes, filename, table_name)
            
            try:
                # Write to a temporary file that DuckDB can access
                temp_path = f"/tmp/{filename}"
                console.log(f"Writing file to virtual filesystem at {temp_path}")
                
                # Write the file to the virtual filesystem
                with open(temp_path, 'wb') as f:
                    f.write(file_bytes)
                
                console.log(f"File written successfully, attempting to read with DuckDB Excel extension...")
                
                # Try different Excel reading approaches
                success = False
                
                # Approach 1: Basic read_xlsx
                try:
                    console.log("Trying basic read_xlsx...")
                    self.conn.execute(f"""
                        CREATE TABLE {table_name} AS 
                        SELECT * FROM read_xlsx('{temp_path}')
                    """)
                    success = True
                    console.log("Basic read_xlsx succeeded")
                except Exception as e1:
                    console.log(f"Basic read_xlsx failed: {e1}")
                
                # Approach 2: With header specification
                if not success:
                    try:
                        console.log("Trying read_xlsx with header=true...")
                        self.conn.execute(f"""
                            CREATE TABLE {table_name} AS 
                            SELECT * FROM read_xlsx('{temp_path}', header=true)
                        """)
                        success = True
                        console.log("read_xlsx with header succeeded")
                    except Exception as e2:
                        console.log(f"read_xlsx with header failed: {e2}")
                
                # Approach 3: With all_varchar
                if not success:
                    try:
                        console.log("Trying read_xlsx with all_varchar=true...")
                        self.conn.execute(f"""
                            CREATE TABLE {table_name} AS 
                            SELECT * FROM read_xlsx('{temp_path}', all_varchar=true)
                        """)
                        success = True
                        console.log("read_xlsx with all_varchar succeeded")
                    except Exception as e3:
                        console.log(f"read_xlsx with all_varchar failed: {e3}")
                        # If all DuckDB approaches fail, try fallback
                        console.log("All DuckDB Excel approaches failed, trying fallback...")
                        return self.load_excel_fallback(file_bytes, filename, table_name)
                
                if success:
                    console.log(f"Table {table_name} created successfully with DuckDB Excel extension")
                    
                    # Get table info
                    count_result = self.conn.execute(f"SELECT COUNT(*) as count FROM {table_name}").fetchone()
                    row_count = count_result[0]
                    console.log(f"Table has {row_count} rows")
                    
                    columns_result = self.conn.execute(f"DESCRIBE {table_name}").fetchall()
                    columns = [row[0] for row in columns_result]
                    console.log(f"Table has columns: {columns}")
                    
                    self.tables[table_name] = {
                        'filename': filename,
                        'rows': row_count,
                        'columns': columns,
                        'size': len(file_bytes),
                        'has_headers': True
                    }
                    
                    console.log(f"Successfully loaded Excel {filename} as {table_name} with {row_count} rows and {len(columns)} columns")
                    return {
                        'success': True,
                        'table_name': table_name,
                        'rows': row_count,
                        'columns': columns,
                        'has_headers': True
                    }
                
            except Exception as excel_error:
                console.error(f"DuckDB Excel processing completely failed: {excel_error}")
                console.log("Attempting fallback Excel processing...")
                return self.load_excel_fallback(file_bytes, filename, table_name)
            
        except Exception as e:
            console.error(f"Failed to load Excel {filename}: {str(e)}")
            return {'success': False, 'error': f'File processing error: {str(e)}. Please ensure the file is a valid Excel (.xlsx) file.'}
    
    def load_excel_fallback(self, file_bytes, filename, table_name):
        """Fallback Excel processing when DuckDB Excel extension is not available"""
        try:
            console.log(f"Using fallback Excel processing for {filename}")
            
            # For now, return a helpful error message
            # In a full implementation, we could use openpyxl or xlsxwriter
            return {
                'success': False,
                'error': f'Excel extension not available in this Pyodide environment. To process {filename}:\n\n1. Convert the file to CSV format using Excel/LibreOffice\n2. If the file has multiple sheets, save each sheet as a separate CSV\n3. Upload the CSV file(s) instead\n\nAlternatively, try a different browser or check if the DuckDB Excel extension can be enabled.'
            }
            
        except Exception as e:
            console.error(f"Fallback Excel processing failed: {e}")
            return {'success': False, 'error': f'Excel processing failed: {str(e)}'}
    
    def list_excel_sheets(self, file_content, filename):
        """List all sheets in an Excel file"""
        try:
            console.log(f"Listing sheets in Excel file: {filename}")
            
            # Decode base64 content to bytes
            file_bytes = base64.b64decode(file_content)
            
            # Write to temporary file
            temp_path = f"/tmp/{filename}"
            with open(temp_path, 'wb') as f:
                f.write(file_bytes)
            
            # Try to get sheet names using DuckDB
            try:
                # This is a hypothetical query - DuckDB might not support sheet listing directly
                result = self.conn.execute(f"SELECT sheet_name FROM read_xlsx_metadata('{temp_path}')").fetchall()
                sheets = [row[0] for row in result]
                console.log(f"Found sheets: {sheets}")
                return {'success': True, 'sheets': sheets}
            except:
                # Fallback - assume single sheet
                console.log("Sheet listing not supported, assuming single sheet")
                return {'success': True, 'sheets': ['Sheet1']}
                
        except Exception as e:
            console.error(f"Failed to list sheets in {filename}: {str(e)}")
            return {'success': False, 'error': str(e), 'sheets': []}
    
    def execute_query(self, sql):
        """Execute SQL query using pure DuckDB"""
        try:
            # Execute query with DuckDB and get results as list
            result = self.conn.execute(sql).fetchall()
            
            # Get column names
            columns = [desc[0] for desc in self.conn.description]
            
            # Convert to list of dictionaries
            data = []
            for row in result:
                data.append({columns[i]: row[i] for i in range(len(columns))})
            
            # Convert to JSON-serializable format
            result_dict = {
                'success': True,
                'rows': len(result),
                'columns': columns,
                'data': data,
                'query': sql
            }
            
            console.log(f"Query executed successfully: {len(result)} rows returned")
            return result_dict
            
        except Exception as e:
            console.error(f"Query failed: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'query': sql
            }
    
    
    def get_table_info(self):
        """Get information about all loaded tables"""
        return {
            'tables': self.tables,
            'count': len(self.tables)
        }
    
    def drop_table(self, table_name):
        """Drop a table from DuckDB"""
        try:
            # Drop from DuckDB
            self.conn.execute(f"DROP TABLE IF EXISTS {table_name}")
            
            # Remove from local tracking
            if table_name in self.tables:
                del self.tables[table_name]
                
            console.log(f"Dropped table {table_name}")
            return {'success': True}
        except Exception as e:
            console.error(f"Failed to drop table {table_name}: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def reload_table_with_headers(self, table_name, file_content, has_headers):
        """Reload an existing table with different header settings"""
        try:
            if table_name not in self.tables:
                return {'success': False, 'error': 'Table not found'}
            
            # Get the original filename
            filename = self.tables[table_name]['filename']
            
            # Drop the existing table
            self.conn.execute(f"DROP TABLE IF EXISTS {table_name}")
            
            # Reload with new header setting (keeping same table name)
            # Temporarily reduce counter since we're reusing the name
            current_counter = self.table_counter
            table_num = int(table_name[1:])  # Extract number from 't1', 't2', etc.
            self.table_counter = table_num
            
            result = self.load_csv_file(file_content, filename, has_headers)
            
            # Restore counter to continue from where we were
            self.table_counter = current_counter
            
            if result['success']:
                result['reloaded'] = True
                console.log(f"Reloaded {table_name} with has_headers={has_headers}")
            
            return result
            
        except Exception as e:
            console.error(f"Failed to reload table {table_name}: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def export_to_csv(self, sql):
        """Export query results to CSV using pure DuckDB"""
        try:
            result = self.conn.execute(sql).fetchall()
            columns = [desc[0] for desc in self.conn.description]
            
            # Build CSV content
            csv_lines = [','.join(columns)]  # Header
            for row in result:
                csv_lines.append(','.join([str(val) if val is not None else '' for val in row]))
            
            csv_content = '\n'.join(csv_lines)
            
            return {
                'success': True,
                'content': csv_content,
                'rows': len(result)
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}
    

# Global instance
csv_tools = DuckDBCSVTools()

# Make it accessible to JavaScript
from js import window
window.csv_tools = csv_tools
    </script>
    
    <!-- JavaScript Application -->
    <script>
        let pyodide;
        let csvTools;
        
        // Initialize PyScript and DuckDB
        async function initializePyScript() {
            try {
                updateLoadingStatus("Loading PyScript runtime...", 20);
                
                // Wait for PyScript to be ready
                await new Promise((resolve) => {
                    document.addEventListener('py:ready', () => {
                        console.log('PyScript ready event received');
                        resolve();
                    });
                });
                
                updateLoadingStatus("Initializing DuckDB...", 60);
                
                // Wait a bit more for Python code to execute
                await new Promise(resolve => setTimeout(resolve, 2000));
                
                // Get the Python CSV tools instance
                window.csvTools = window.csv_tools;
                csvTools = window.csv_tools;
                
                updateLoadingStatus("Ready!", 100);
                
                // Initialize UI
                setTimeout(() => {
                    initializeUI();
                }, 500);
                
            } catch (error) {
                console.error('Failed to initialize PyScript:', error);
                showError(`Initialization failed: ${error.message}`);
            }
        }
        
        function updateLoadingStatus(message, progress = 0) {
            const statusElement = document.getElementById('loading-status');
            const progressBar = document.getElementById('loading-bar');
            
            if (statusElement) {
                statusElement.textContent = message;
            }
            if (progressBar) {
                progressBar.style.width = `${progress}%`;
            }
        }
        
        function initializeUI() {
            // Hide loading and show main sections
            document.getElementById('loading-status').style.display = 'none';
            document.querySelector('.loading-progress').style.display = 'none';
            document.getElementById('upload-section').style.display = 'block';
            document.getElementById('query-section').style.display = 'block';
            document.getElementById('results-section').style.display = 'block';
            
            // Initialize SQL editor
            initializeSQLEditor();
            
            // Initialize file upload
            initializeFileUpload();
            
            // Initialize event listeners
            initializeEventListeners();
            
            console.log('Pyodide CSV Tools ready!');
        }
        
        function initializeSQLEditor() {
            window.sqlEditor = CodeMirror(document.getElementById('sql-editor'), {
                mode: 'text/x-sql',
                theme: 'default',
                lineNumbers: true,
                autoCloseBrackets: true,
                matchBrackets: true,
                indentUnit: 2,
                lineWrapping: true,
                value: '-- Welcome to CSV Tools with DuckDB!\n-- Upload some files and start querying\n\nSELECT * FROM t1 LIMIT 10;'
            });
        }
        
        function initializeFileUpload() {
            const dropzone = document.getElementById('dropzone');
            const fileInput = document.createElement('input');
            fileInput.type = 'file';
            fileInput.accept = '.csv,.xlsx';
            fileInput.multiple = true;
            fileInput.style.display = 'none';
            document.body.appendChild(fileInput);
            
            dropzone.addEventListener('click', () => fileInput.click());
            dropzone.addEventListener('dragover', handleDragOver);
            dropzone.addEventListener('drop', handleDrop);
            dropzone.addEventListener('dragenter', handleDragEnter);
            dropzone.addEventListener('dragleave', handleDragLeave);
            
            fileInput.addEventListener('change', handleFileSelect);
        }
        
        function initializeEventListeners() {
            document.getElementById('run-query').addEventListener('click', executeQuery);
            document.getElementById('export-csv').addEventListener('click', exportToCSV);
            document.getElementById('example-queries').addEventListener('change', loadExampleQuery);
            
            // Keyboard shortcuts
            document.addEventListener('keydown', (e) => {
                if ((e.ctrlKey || e.metaKey) && e.key === 'Enter') {
                    e.preventDefault();
                    executeQuery();
                }
            });
        }
        
        // File handling functions
        function handleDragOver(e) {
            e.preventDefault();
            e.currentTarget.classList.add('dragover');
        }
        
        function handleDragEnter(e) {
            e.preventDefault();
            e.currentTarget.classList.add('dragover');
        }
        
        function handleDragLeave(e) {
            e.preventDefault();
            e.currentTarget.classList.remove('dragover');
        }
        
        function handleDrop(e) {
            e.preventDefault();
            e.currentTarget.classList.remove('dragover');
            const files = Array.from(e.dataTransfer.files);
            processFiles(files);
        }
        
        function handleFileSelect(e) {
            const files = Array.from(e.target.files);
            processFiles(files);
            e.target.value = '';
        }
        
        async function processFiles(files) {
            for (const file of files) {
                await processFile(file);
            }
            updateFileList();
        }
        
        // Store file contents for reprocessing
        window.fileContents = new Map();
        
        async function processFile(file) {
            try {
                showInfo(`Processing ${file.name}...`);
                
                const isExcel = file.name.match(/\\.xlsx$/i);
                const isOldExcel = file.name.match(/\\.xls$/i);
                
                if (isOldExcel) {
                    // Handle old .xls format (not supported by DuckDB)
                    showError(`${file.name} uses the old .xls format which is not supported. Please save as .xlsx format instead.`);
                } else if (isExcel) {
                    // Process Excel file using official DuckDB Excel extension
                    console.log(`Processing Excel file: ${file.name}, size: ${file.size} bytes`);
                    
                    const arrayBuffer = await file.arrayBuffer();
                    const base64Content = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
                    console.log(`Converted to base64, length: ${base64Content.length}`);
                    
                    const resultRaw = window.csv_tools.load_excel_file(base64Content, file.name);
                    const result = resultRaw.toJs ? resultRaw.toJs() : resultRaw;
                    
                    console.log('Excel processing result:', result);
                    
                    if (result.success) {
                        showSuccess(`Loaded Excel file ${file.name} as ${result.table_name} (${result.rows} rows, ${result.columns.length} columns)`);
                        updateSQLEditorWithTables();
                    } else {
                        console.error('Excel loading failed:', result.error);
                        showError(`Failed to load ${file.name}: ${result.error}`);
                    }
                } else {
                    // Process CSV file with default headers = true
                    const content = await file.text();
                    
                    // Store file content for potential reprocessing
                    window.fileContents.set(file.name, content);
                    
                    const resultRaw = window.csv_tools.load_csv_file(content, file.name, true);
                    const result = resultRaw.toJs ? resultRaw.toJs() : resultRaw;
                    
                    if (result.success) {
                        showSuccess(`Loaded ${file.name} as ${result.table_name} (${result.rows} rows)`);
                        updateSQLEditorWithTables();
                    } else {
                        showError(`Failed to load ${file.name}: ${result.error}`);
                    }
                }
                
            } catch (error) {
                console.error('File processing error:', error);
                showError(`Error processing ${file.name}: ${error.message}`);
            }
        }
        
        function updateSQLEditorWithTables() {
            const tableInfoRaw = window.csv_tools.get_table_info();
            const tableInfo = tableInfoRaw.toJs ? tableInfoRaw.toJs() : tableInfoRaw;
            const tableNames = Object.keys(tableInfo.tables);
            
            if (tableNames.length > 0) {
                const comment = `-- Available tables: ${tableNames.join(', ')}\\n\\n`;
                const currentValue = window.sqlEditor.getValue();
                if (!currentValue.includes('Available tables:')) {
                    window.sqlEditor.setValue(comment + currentValue);
                }
            }
        }
        
        function updateFileList() {
            const tableInfoRaw = window.csv_tools.get_table_info();
            const tableInfo = tableInfoRaw.toJs ? tableInfoRaw.toJs() : tableInfoRaw;
            const fileListContainer = document.getElementById('file-list');
            
            if (Object.keys(tableInfo.tables).length === 0) {
                fileListContainer.innerHTML = '<p class="no-files">No files loaded yet</p>';
                return;
            }
            
            let html = '<div class="uploaded-files">';
            for (const [tableName, info] of Object.entries(tableInfo.tables)) {
                const isCSV = info.filename.toLowerCase().endsWith('.csv');
                const hasHeaders = info.has_headers !== undefined ? info.has_headers : true;
                
                html += `
                    <div class="file-item">
                        <div class="file-info">
                            <span class="file-name">${info.filename}</span>
                            <span class="table-alias">→ ${tableName}</span>
                        </div>
                        <div class="file-stats">
                            ${info.rows.toLocaleString()} rows, ${info.columns.length} columns
                        </div>`;
                        
                // Add header toggle for CSV files only
                if (isCSV) {
                    html += `
                        <div class="header-toggle">
                            <input type="checkbox" id="header-${tableName}" ${hasHeaders ? 'checked' : ''} 
                                   onchange="toggleHeaders('${tableName}', this.checked)">
                            <label for="header-${tableName}">File has headers</label>
                        </div>`;
                }
                
                // Show the actual headers
                html += `
                        <div class="file-headers">
                            <strong>Columns:</strong>
                            <div class="header-list">${info.columns.join(', ')}</div>
                        </div>
                        <div class="file-actions">
                            <button onclick="removeTable('${tableName}')" class="remove-btn">Remove</button>
                        </div>
                    </div>`;
            }
            html += '</div>';
            fileListContainer.innerHTML = html;
        }
        
        async function executeQuery() {
            try {
                const sql = window.sqlEditor.getValue().trim();
                if (!sql) {
                    showError('Please enter a SQL query');
                    return;
                }
                
                showInfo('Executing query...');
                
                const result = window.csv_tools.execute_query(sql);
                
                // Convert PyScript result to JavaScript object
                const jsResult = result.toJs ? result.toJs() : result;
                
                if (jsResult.success) {
                    displayResults(jsResult);
                    showSuccess(`Query executed: ${jsResult.rows} rows returned`);
                } else {
                    showError(`Query failed: ${jsResult.error}`);
                    clearResults();
                }
                
            } catch (error) {
                console.error('Query execution error:', error);
                showError(`Query execution failed: ${error.message}`);
                clearResults();
            }
        }
        
        function displayResults(result) {
            const resultsContainer = document.getElementById('results-table');
            const queryInfo = document.getElementById('query-info');
            
            // Show query info
            queryInfo.innerHTML = `
                <div class="query-summary">
                    <strong>${result.rows.toLocaleString()}</strong> rows, 
                    <strong>${result.columns.length}</strong> columns
                </div>
            `;
            
            if (result.rows === 0) {
                resultsContainer.innerHTML = '<p class="no-results">Query returned no results</p>';
                return;
            }
            
            // Create table
            let html = '<table class="results-table"><thead><tr>';
            result.columns.forEach(col => {
                html += `<th>${escapeHtml(col)}</th>`;
            });
            html += '</tr></thead><tbody>';
            
            // Show first 1000 rows
            const displayRows = result.data.slice(0, 1000);
            displayRows.forEach(row => {
                html += '<tr>';
                result.columns.forEach(col => {
                    const value = row[col];
                    html += `<td>${escapeHtml(String(value ?? ''))}</td>`;
                });
                html += '</tr>';
            });
            html += '</tbody></table>';
            
            if (result.rows > 1000) {
                html += `<p class="display-note">Showing first 1,000 rows of ${result.rows.toLocaleString()} total rows. Use LIMIT in your query or export for full results.</p>`;
            }
            
            resultsContainer.innerHTML = html;
            
            // Store current query for export
            window.currentQuery = result.query;
        }
        
        function clearResults() {
            document.getElementById('results-table').innerHTML = '';
            document.getElementById('query-info').innerHTML = '';
            window.currentQuery = null;
        }
        
        async function exportToCSV() {
            if (!window.currentQuery) {
                showError('No query results to export');
                return;
            }
            
            try {
                const resultRaw = window.csv_tools.export_to_csv(window.currentQuery);
                const result = resultRaw.toJs ? resultRaw.toJs() : resultRaw;
                
                if (result.success) {
                    downloadFile(result.content, 'query_results.csv', 'text/csv');
                    showSuccess(`Exported ${result.rows} rows to CSV`);
                } else {
                    showError(`Export failed: ${result.error}`);
                }
            } catch (error) {
                showError(`Export failed: ${error.message}`);
            }
        }
        
        
        function downloadFile(content, filename, mimeType) {
            const blob = new Blob([content], { type: mimeType });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }
        
        function loadExampleQuery() {
            const select = document.getElementById('example-queries');
            const query = select.value;
            if (query) {
                window.sqlEditor.setValue(query);
                select.value = '';
            }
        }
        
        async function toggleHeaders(tableName, hasHeaders) {
            try {
                const tableInfoRaw = window.csv_tools.get_table_info();
                const tableInfo = tableInfoRaw.toJs ? tableInfoRaw.toJs() : tableInfo;
                const info = tableInfo.tables[tableName];
                
                if (!info) {
                    showError('Table not found');
                    return;
                }
                
                // Get the stored file content
                const fileContent = window.fileContents.get(info.filename);
                if (!fileContent) {
                    showError('Original file content not available. Please re-upload the file.');
                    return;
                }
                
                showInfo(`Reloading ${info.filename} with ${hasHeaders ? 'headers' : 'no headers'}...`);
                
                // Reload the table with new header setting
                const resultRaw = window.csv_tools.reload_table_with_headers(tableName, fileContent, hasHeaders);
                const result = resultRaw.toJs ? resultRaw.toJs() : resultRaw;
                
                if (result.success) {
                    updateFileList();
                    updateSQLEditorWithTables();
                    showSuccess(`Reloaded ${info.filename} ${hasHeaders ? 'with' : 'without'} headers`);
                } else {
                    showError(`Failed to reload table: ${result.error}`);
                    // Revert checkbox on failure
                    const checkbox = document.getElementById(`header-${tableName}`);
                    if (checkbox) {
                        checkbox.checked = !hasHeaders;
                    }
                }
                
            } catch (error) {
                console.error('Header toggle error:', error);
                showError(`Error toggling headers: ${error.message}`);
                // Revert checkbox on failure
                const checkbox = document.getElementById(`header-${tableName}`);
                if (checkbox) {
                    checkbox.checked = !hasHeaders;
                }
            }
        }
        
        function removeTable(tableName) {
            const resultRaw = window.csv_tools.drop_table(tableName);
            const result = resultRaw.toJs ? resultRaw.toJs() : resultRaw;
            if (result.success) {
                // Also remove stored file content
                const tableInfoRaw = window.csv_tools.get_table_info();
                const tableInfo = tableInfoRaw.toJs ? tableInfoRaw.toJs() : tableInfoRaw;
                const info = tableInfo.tables[tableName];
                if (info) {
                    window.fileContents.delete(info.filename);
                }
                
                updateFileList();
                showInfo(`Removed table ${tableName}`);
            } else {
                showError(`Failed to remove table: ${result.error}`);
            }
        }
        
        // Utility functions
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }
        
        function showError(message) {
            showNotification(message, 'error');
        }
        
        function showSuccess(message) {
            showNotification(message, 'success');
        }
        
        function showInfo(message) {
            showNotification(message, 'info');
        }
        
        function showNotification(message, type = 'info') {
            // Remove existing notifications of the same type
            const existing = document.querySelectorAll(`.notification.${type}`);
            existing.forEach(el => el.remove());
            
            // Create notification element
            const notification = document.createElement('div');
            notification.className = `notification ${type}`;
            
            // Set styling based on type
            const styles = {
                error: { backgroundColor: '#e74c3c', color: 'white' },
                success: { backgroundColor: '#27ae60', color: 'white' },
                info: { backgroundColor: '#3498db', color: 'white' }
            };
            
            Object.assign(notification.style, {
                position: 'fixed',
                top: '20px',
                right: '20px',
                padding: '15px 20px',
                borderRadius: '6px',
                boxShadow: '0 4px 6px rgba(0,0,0,0.1)',
                zIndex: '1000',
                maxWidth: '400px',
                wordWrap: 'break-word',
                ...styles[type]
            });
            
            notification.textContent = message;
            document.body.appendChild(notification);
            
            // Auto-remove
            const timeout = type === 'error' ? 8000 : type === 'success' ? 4000 : 6000;
            setTimeout(() => {
                if (notification.parentNode) {
                    notification.parentNode.removeChild(notification);
                }
            }, timeout);
        }
        
        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', initializePyScript);
    </script>
</body>
</html>